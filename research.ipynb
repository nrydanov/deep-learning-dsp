{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guitar amplifier emulation research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import IPython"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining required constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = \"data/in.wav\"\n",
    "OUTPUT_PATH = \"data/out.wav\"\n",
    "\n",
    "TEST_INPUT_PATH = \"data/in.wav\"\n",
    "TEST_OUTPUT_PATH = \"data/out.wav\"\n",
    "\n",
    "TRAIN_PER_EPOCH = 15 # seconds\n",
    "VAL_DURATION = 10 # seconds\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "INFERENCE_BATCH_SIZE = 256\n",
    "\n",
    "INPUT_SIZE = 441\n",
    "MODEL_NAME = input()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataset from audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import RawWaveformLoader\n",
    "\n",
    "train, valid, _ = RawWaveformLoader.DataSplitter(input_path=INPUT_PATH, \n",
    "                                                  output_path=OUTPUT_PATH, \n",
    "                                                  train_per_epoch=TRAIN_PER_EPOCH, \n",
    "                                                  valid_time=VAL_DURATION, \n",
    "                                                  batch_size=BATCH_SIZE,\n",
    "                                                  input_size=INPUT_SIZE,\n",
    "                                                  dynamic_train=False).split()\n",
    "\n",
    "demo = RawWaveformLoader(input_path=TEST_INPUT_PATH, \n",
    "                         output_path=TEST_OUTPUT_PATH, \n",
    "                         batch_size=INFERENCE_BATCH_SIZE,\n",
    "                         input_size=INPUT_SIZE, \n",
    "                         interval_duration=10, \n",
    "                         start_offset=86,\n",
    "                         end_offset=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Add, BatchNormalization, TimeDistributed\n",
    "\n",
    "from metrics import error_to_signal\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "HIDDEN_UNITS = 92\n",
    "\n",
    "K.clear_session()\n",
    "input_layer = Input(batch_shape=(BATCH_SIZE, INPUT_SIZE, 1))\n",
    "rnn = LSTM(HIDDEN_UNITS, return_sequences=True)(input_layer)\n",
    "rnn = BatchNormalization()(rnn)\n",
    "rnn = Dense(1)(rnn)\n",
    "added = Add()([input_layer, rnn])\n",
    "\n",
    "model = Model(inputs=[input_layer], outputs=added)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=Adam(LEARNING_RATE), loss='mse', metrics=['mse', error_to_signal, 'mae'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import BackupAndRestore, CSVLogger, TensorBoard, ReduceLROnPlateau\n",
    "\n",
    "from callbacks import CheckpointAndSave\n",
    "    \n",
    "callbacks = [\n",
    "  BackupAndRestore(f'{MODEL_NAME}/backup'),\n",
    "  # CheckpointAndSave(f'{MODEL_NAME}/mse_checkpoint', demo, model, BATCH_SIZE, save_best_only=True, save_weights_only=True, monitor='val_mse', verbose=1),\n",
    "  # CheckpointAndSave(f'{MODEL_NAME}/ets_checkpoint', demo, model, BATCH_SIZE, save_best_only=True, save_weights_only=True, monitor='val_error_to_signal', verbose=1),\n",
    "  # CheckpointAndSave(f'{MODEL_NAME}/mae_checkpoint', demo, model, BATCH_SIZE, save_best_only=True, save_weights_only=True, monitor='val_mae', verbose=1),\n",
    "  # ReduceLROnPlateau(patience=10, factor=0.5, cooldown=10, monitor='loss', min_lr=1e-5),\n",
    "  TensorBoard(log_dir=f'{MODEL_NAME}/logs'),\n",
    "  CSVLogger(f'{MODEL_NAME}/logs.csv', append=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train[0][0], train[0][1], batch_size=BATCH_SIZE, shuffle=True, epochs=10000, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(train, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "wavfile.write('out.wav', 44100, pred.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy\n",
    "\n",
    "norm = math.sqrt(sum(numpy.sum(K.get_value(w)) for w in model.optimizer.weights))\n",
    "norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "0e1565b582b08c8435dd4e4deaf762f9971db0b4896f2676b7c0eb8ce2624cff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
