{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guitar Amplifier Emulation Research"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Dense, Input, Add, Conv1D, BatchNormalization, Dropout\n",
    "from keras.callbacks import BackupAndRestore, CSVLogger, TensorBoard, ModelCheckpoint\n",
    "\n",
    "from callbacks import CheckpointAndSave, CosineAnnealingScheduler\n",
    "from metrics import error_to_signal\n",
    "from dataset import DirectSTFTLoader, DirectWaveformLoader, WindowWaveformLoader, DataSplitter, WindowSTFTLoader\n",
    "from utils import save_attempt_data\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = \"data/float32/clean.wav\"\n",
    "OUTPUT_PATH = \"data/float32/amp.wav\"\n",
    "\n",
    "TEST_INPUT_PATH = \"data/float32/test_in.wav\"\n",
    "TEST_OUTPUT_PATH = \"data/float32/test_out.wav\"\n",
    "\n",
    "WORK_DIR = \"models\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic LSTM, $y_k = f(c_{k - 1}, h_{k - 1}, x_k), k = [0, n)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining required values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2 ** 5 # in samples\n",
    "inference_batch_size = 1 # in samples\n",
    "input_size = 22050 # in samples\n",
    "duration = 15 * 60 # in seconds\n",
    "epochs = 750"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataset from audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = DataSplitter(input_path=INPUT_PATH,\n",
    "                            output_path=OUTPUT_PATH,\n",
    "                            duration=duration,\n",
    "                            batch_size=batch_size,\n",
    "                            input_size=input_size,\n",
    "                            preemphasis=True).split(DirectWaveformLoader)\n",
    "\n",
    "demo = DirectWaveformLoader(input_path=INPUT_PATH,\n",
    "                            output_path=OUTPUT_PATH,\n",
    "                            batch_size=inference_batch_size,\n",
    "                            input_size=input_size, \n",
    "                            duration=10,\n",
    "                            offset=86,\n",
    "                            preemphasis=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "hidden_units = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "input_layer = Input(batch_shape=(batch_size, input_size, 1))\n",
    "rnn = LSTM(hidden_units, return_sequences=True)(input_layer)\n",
    "rnn = Dense(1)(rnn)\n",
    "add = Add()([input_layer, rnn])\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=[rnn])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate), loss='mse', metrics=['mse', error_to_signal, 'mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = input()\n",
    "\n",
    "if model_name == \"\":\n",
    "  raise ValueError(\"Enter model name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolder = f\"{WORK_DIR}/{model_name}\"\n",
    "save_attempt_data(subfolder, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "  BackupAndRestore(f'{subfolder}/backup'),\n",
    "  CheckpointAndSave(f'{subfolder}/mse_checkpoint/', demo, model, inference_batch_size, save_best_only=True, save_weights_only=True, monitor='val_mse', verbose=1),\n",
    "  CheckpointAndSave(f'{subfolder}/ets_checkpoint/', demo, model, inference_batch_size, save_best_only=True, save_weights_only=True, monitor='val_error_to_signal', verbose=1),\n",
    "  CheckpointAndSave(f'{subfolder}/mae_checkpoint/', demo, model, inference_batch_size, save_best_only=True, save_weights_only=True, monitor='val_mae', verbose=1),\n",
    "  TensorBoard(log_dir=f'{subfolder}/logs'),\n",
    "  CSVLogger(f'{subfolder}/logs.csv', append=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train, validation_data=valid, shuffle=True, epochs=epochs, callbacks=callbacks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining required values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2 ** 14 # in samples\n",
    "input_size = 150 # in samples\n",
    "epochs = 100\n",
    "duration = 30 * 60 # in seconds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataset from audio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$a_n = f(a_{n - 1}, a_{n - 2}, \\dots, a_{n - k})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = DataSplitter(input_path=INPUT_PATH, \n",
    "                            output_path=OUTPUT_PATH,\n",
    "                            batch_size=batch_size,\n",
    "                            duration=duration,\n",
    "                            input_size=input_size,\n",
    "                            preemphasis=True).split(WindowWaveformLoader)\n",
    "\n",
    "demo = WindowWaveformLoader(input_path=TEST_INPUT_PATH,\n",
    "                            output_path=TEST_OUTPUT_PATH,\n",
    "                            batch_size=batch_size,\n",
    "                            input_size=input_size,\n",
    "                            duration=10,\n",
    "                            offset=86,\n",
    "                            preemphasis=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.004\n",
    "conv1d_strides = 3\n",
    "conv1d_filters = 32\n",
    "hidden_units = 36\n",
    "kernel_size = 5\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "input_layer = Input((input_size, 1))\n",
    "conv1d = Conv1D(conv1d_filters, kernel_size, strides=conv1d_strides, activation=None, padding='same')(input_layer)\n",
    "conv1d = Conv1D(conv1d_filters, kernel_size, strides=conv1d_strides, activation=None, padding='same')(conv1d)\n",
    "rnn = LSTM(hidden_units)(conv1d)\n",
    "rnn = Dropout(0.2)(rnn)\n",
    "rnn = BatchNormalization()(rnn)\n",
    "rnn = Dense(1, activation=None)(rnn)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=[rnn])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate), loss='mse', metrics=['mse', error_to_signal, 'mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = input()\n",
    "\n",
    "if model_name == \"\":\n",
    "  raise ValueError(\"Enter model name\")\n",
    "\n",
    "subfolder = f\"{WORK_DIR}/{model_name}\"\n",
    "save_attempt_data(subfolder, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "  CosineAnnealingScheduler(5, 4e-3, 1e-3),\n",
    "  BackupAndRestore(f'{subfolder}/backup'),\n",
    "  CheckpointAndSave(f'{subfolder}/mse_checkpoint/', demo, model, batch_size, save_best_only=True, save_weights_only=True, monitor='val_mse', verbose=1),\n",
    "  CheckpointAndSave(f'{subfolder}/ets_checkpoint/', demo, model, batch_size, save_best_only=True, save_weights_only=True, monitor='val_error_to_signal', verbose=1),\n",
    "  CheckpointAndSave(f'{subfolder}/mae_checkpoint/', demo, model, batch_size, save_best_only=True, save_weights_only=True, monitor='val_mae', verbose=1),\n",
    "  TensorBoard(log_dir=f'{subfolder}/logs'),\n",
    "  CSVLogger(f'{subfolder}/logs.csv', append=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train, validation_data=valid, shuffle=True, epochs=epochs, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(demo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STFT Transform approach"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining required values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2 ** 5\n",
    "inference_batch_size = 2 ** 5\n",
    "input_size = 4410\n",
    "duration = 3 * 60 # in seconds\n",
    "epochs = 100\n",
    "\n",
    "n_fft = 512\n",
    "hop_length = 128"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataset from audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = DataSplitter(input_path=INPUT_PATH, \n",
    "                            output_path=OUTPUT_PATH,\n",
    "                            batch_size=batch_size,\n",
    "                            duration=duration,\n",
    "                            input_size=input_size,\n",
    "                            preemphasis=True).split(DirectSTFTLoader, n_fft=512, hop_length=128)\n",
    "\n",
    "demo = DirectSTFTLoader(input_path=TEST_INPUT_PATH, \n",
    "                       output_path=TEST_OUTPUT_PATH, \n",
    "                       batch_size=inference_batch_size,\n",
    "                       input_size=input_size, \n",
    "                       duration=10, \n",
    "                       offset=86,\n",
    "                       preemphasis=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size = train[0][0].shape[2]\n",
    "learning_rate = 0.001\n",
    "hidden_units = 64\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "input_layer = Input(batch_shape=train[0][0].shape)\n",
    "rnn = LSTM(hidden_units, return_sequences=True)(input_layer)\n",
    "rnn = Dense(train[0][0].shape[2])(rnn)\n",
    "add = Add()([input_layer, rnn])\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=[rnn])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate), loss='mse', metrics=['mse', 'mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = input()\n",
    "\n",
    "if model_name == \"\":\n",
    "  raise ValueError(\"Enter model name\")\n",
    "\n",
    "subfolder = f\"{WORK_DIR}/{model_name}\"\n",
    "save_attempt_data(subfolder, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "  CosineAnnealingScheduler(5, 4e-3, 1e-3),\n",
    "  BackupAndRestore(f'{subfolder}/backup'),\n",
    "  ModelCheckpoint(f'{subfolder}/mse_checkpoint/', save_best_only=True, save_weights_only=True, monitor='val_mse', verbose=1),\n",
    "  ModelCheckpoint(f'{subfolder}/mae_checkpoint/', save_best_only=True, save_weights_only=True, monitor='val_mae', verbose=1),\n",
    "  TensorBoard(log_dir=f'{subfolder}/logs'),\n",
    "  CSVLogger(f'{subfolder}/logs.csv', append=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train, validation_data=valid, shuffle=True, epochs=epochs, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(train, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import output_to_audio\n",
    "\n",
    "result = output_to_audio(pred, n_fft=n_fft, hop_length=hop_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "wavfile.write(\"out.wav\", 44100, result.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining required values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2 ** 12\n",
    "input_size = 441\n",
    "epochs = 100\n",
    "duration = 3 * 60 # in seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataset from audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$a_n = f(a_{n - 1}, a_{n - 2}, \\dots, a_{n - k})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = DataSplitter(input_path=INPUT_PATH,\n",
    "                            output_path=OUTPUT_PATH,\n",
    "                            batch_size=batch_size,\n",
    "                            duration=duration,\n",
    "                            input_size=input_size,\n",
    "                            preemphasis=True).split(WindowSTFTLoader, n_fft=128, hop_length=32)\n",
    "\n",
    "demo = WindowSTFTLoader(input_path=TEST_INPUT_PATH,\n",
    "                        output_path=TEST_OUTPUT_PATH,\n",
    "                        batch_size=batch_size,\n",
    "                        input_size=input_size,\n",
    "                        duration=10,\n",
    "                        offset=86,\n",
    "                        preemphasis=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.004\n",
    "conv1d_strides = 6\n",
    "conv1d_filters = 32\n",
    "hidden_units = 36\n",
    "kernel_size = 12\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "input_layer = Input((first_batch.shape[1], first_batch.shape[2]))\n",
    "rnn = LSTM(hidden_units)(input_layer)\n",
    "rnn = Dropout(0.2)(rnn)\n",
    "rnn = BatchNormalization()(rnn)\n",
    "rnn = Dense(1, activation=None)(rnn)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=[rnn])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate), loss='mse', metrics=['mse', error_to_signal, 'mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = input()\n",
    "\n",
    "if model_name == \"\":\n",
    "  raise ValueError(\"Enter model name\")\n",
    "\n",
    "subfolder = f\"{WORK_DIR}/{model_name}\"\n",
    "save_attempt_data(subfolder, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "  CosineAnnealingScheduler(5, 4e-3, 1e-3),\n",
    "  BackupAndRestore(f'{subfolder}/backup'),\n",
    "  # CheckpointAndSave(f'{subfolder}/mse_checkpoint/', demo, model, batch_size, save_best_only=True, save_weights_only=True, monitor='val_mse', verbose=1),\n",
    "  # CheckpointAndSave(f'{subfolder}/ets_checkpoint/', demo, model, batch_size, save_best_only=True, save_weights_only=True, monitor='val_error_to_signal', verbose=1),\n",
    "  # CheckpointAndSave(f'{subfolder}/mae_checkpoint/', demo, model, batch_size, save_best_only=True, save_weights_only=True, monitor='val_mae', verbose=1),\n",
    "  TensorBoard(log_dir=f'{subfolder}/logs'),\n",
    "  CSVLogger(f'{subfolder}/logs.csv', append=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train, validation_data=valid, shuffle=True, epochs=epochs, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(demo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "0e1565b582b08c8435dd4e4deaf762f9971db0b4896f2676b7c0eb8ce2624cff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
