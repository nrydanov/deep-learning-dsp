{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guitar amplifier emulation research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import IPython\n",
    "import git\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import LSTM, Dense, Input, Add, Conv1D\n",
    "\n",
    "from keras.callbacks import BackupAndRestore, CSVLogger, TensorBoard\n",
    "\n",
    "from callbacks import CheckpointAndSave\n",
    "from metrics import error_to_signal\n",
    "from dataset import RawWaveformLoader, WindowWaveformLoader, DataSplitter\n",
    "from utils import save_attempt_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = \"data/float32/test_in.wav\"\n",
    "OUTPUT_PATH = \"data/float32/test_out.wav\"\n",
    "\n",
    "TEST_INPUT_PATH = \"data/float32/test_in.wav\"\n",
    "TEST_OUTPUT_PATH = \"data/float32/test_out.wav\"\n",
    "\n",
    "WORK_DIR = \"models\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$a_n = w * h_n + x, n = [0, k)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining required values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2 ** 8\n",
    "input_size = 150 # samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataset from audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = DataSplitter(input_path=INPUT_PATH, \n",
    "                            output_path=OUTPUT_PATH,\n",
    "                            batch_size=batch_size,\n",
    "                            input_size=input_size,\n",
    "                            preemphasis=True).split(RawWaveformLoader)\n",
    "\n",
    "demo = RawWaveformLoader(input_path=TEST_INPUT_PATH, \n",
    "                         output_path=TEST_OUTPUT_PATH, \n",
    "                         batch_size=batch_size,\n",
    "                         input_size=input_size, \n",
    "                         duration=10, \n",
    "                         offset=86,\n",
    "                         preemphasis=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "hidden_units = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "input_layer = Input((150, 1))\n",
    "rnn = LSTM(hidden_units, return_sequences=True)(input_layer)\n",
    "rnn = Dense(1)(rnn)\n",
    "\n",
    "add = Add()([input_layer, rnn])\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=[add])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate), loss='mse', metrics=['mse', error_to_signal, 'mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = input()\n",
    "\n",
    "if model_name == \"\":\n",
    "  raise ValueError(\"Enter model name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolder = f\"{WORK_DIR}/{model_name}\"\n",
    "save_attempt_data(subfolder, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "  BackupAndRestore(f'{subfolder}/backup'),\n",
    "  CheckpointAndSave(f'{subfolder}/mse_checkpoint/', demo, model, batch_size, save_best_only=True, save_weights_only=True, monitor='val_mse', verbose=1),\n",
    "  CheckpointAndSave(f'{subfolder}/ets_checkpoint/', demo, model, batch_size, save_best_only=True, save_weights_only=True, monitor='val_error_to_signal', verbose=1),\n",
    "  CheckpointAndSave(f'{subfolder}/mae_checkpoint/', demo, model, batch_size, save_best_only=True, save_weights_only=True, monitor='val_mae', verbose=1),\n",
    "  TensorBoard(log_dir=f'{subfolder}/logs'),\n",
    "  CSVLogger(f'{subfolder}/logs.csv', append=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "model.fit(train, validation_data=valid, shuffle=True, epochs=epochs, callbacks=callbacks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataset from audio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$a_n = f(a_{n - 1}, a_{n - 2}, \\dots, a_{n - k})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = DataSplitter(input_path=INPUT_PATH, \n",
    "                            output_path=OUTPUT_PATH,\n",
    "                            batch_size=batch_size,\n",
    "                            input_size=input_size,\n",
    "                            preemphasis=True).split(WindowWaveformLoader)\n",
    "\n",
    "demo = WindowWaveformLoader(input_path=TEST_INPUT_PATH, \n",
    "                         output_path=TEST_OUTPUT_PATH, \n",
    "                         batch_size=batch_size,\n",
    "                         input_size=input_size, \n",
    "                         duration=10, \n",
    "                         offset=86,\n",
    "                         preemphasis=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "conv1d_strides = 12\n",
    "conv1d_filters = 16\n",
    "hidden_units = 36\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "input_layer = Input(150, 1)\n",
    "rnn = LSTM(hidden_units)(input_layer)\n",
    "rnn = Dense(1)(rnn)\n",
    "\n",
    "add = Add([input_layer, rnn])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(conv1d_filters, 12, strides=conv1d_strides, activation=None, padding='same', input_shape=(input_size,1)))\n",
    "model.add(Conv1D(conv1d_filters, 12, strides=conv1d_strides, activation=None, padding='same'))\n",
    "model.add(LSTM(hidden_units))\n",
    "model.add(Dense(1, activation=None))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate), loss='mse', metrics=['mse', error_to_signal, 'mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import save_attempt_data\n",
    "    \n",
    "subfolder = f\"{WORK_DIR}/{model_name}\"\n",
    "\n",
    "save_attempt_data(subfolder, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train, validation_data=valid, shuffle=True, epochs=epochs, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(demo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "0e1565b582b08c8435dd4e4deaf762f9971db0b4896f2676b7c0eb8ce2624cff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
