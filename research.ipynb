{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guitar amplifier emulation research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import IPython\n",
    "import git"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining required constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = \"data/float32/test_in.wav\"\n",
    "OUTPUT_PATH = \"data/float32/test_out.wav\"\n",
    "\n",
    "TEST_INPUT_PATH = \"data/float32/test_in.wav\"\n",
    "TEST_OUTPUT_PATH = \"data/float32/test_out.wav\"\n",
    "\n",
    "BATCH_SIZE = 2 ** 14\n",
    "INFERENCE_BATCH_SIZE = 44\n",
    "SAMPLES_PER_EPOCH = 0.1 # min = 0, max = 1\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "INPUT_SIZE = 150 # samples\n",
    "MODEL_NAME = input()\n",
    "\n",
    "if MODEL_NAME == \"\":\n",
    "  raise ValueError(\"Enter model name\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataset from audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import RawWaveformLoader\n",
    "\n",
    "train, valid = RawWaveformLoader.DataSplitter(input_path=INPUT_PATH, \n",
    "                                              output_path=OUTPUT_PATH,\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              input_size=INPUT_SIZE,\n",
    "                                              preemphasis=True).split()\n",
    "\n",
    "demo = RawWaveformLoader(input_path=TEST_INPUT_PATH, \n",
    "                         output_path=TEST_OUTPUT_PATH, \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         input_size=INPUT_SIZE, \n",
    "                         duration=10, \n",
    "                         offset=86,\n",
    "                         preemphasis=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(train.x, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(train.y, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Conv1D\n",
    "\n",
    "from metrics import error_to_signal\n",
    "\n",
    "LEARNING_RATE = 0.01\n",
    "HIDDEN_UNITS = 64\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "conv1d_strides = 12\n",
    "conv1d_filters = 16\n",
    "hidden_units = 36\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(conv1d_filters, 12, strides=conv1d_strides, activation=None, padding='same', input_shape=(INPUT_SIZE,1)))\n",
    "model.add(Conv1D(conv1d_filters, 12, strides=conv1d_strides, activation=None, padding='same'))\n",
    "model.add(LSTM(hidden_units))\n",
    "model.add(Dense(1, activation=None))\n",
    "\n",
    "model.compile(optimizer=Adam(LEARNING_RATE), loss=error_to_signal, metrics=['mse', error_to_signal, 'mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import BackupAndRestore, CSVLogger, TensorBoard\n",
    "\n",
    "from callbacks import CheckpointAndSave, CosineAnnealingScheduler\n",
    "\n",
    "from utils import save_attempt_data\n",
    "    \n",
    "FOLDER = \"models\"\n",
    "subfolder = f\"{FOLDER}/{MODEL_NAME}\"\n",
    "\n",
    "save_attempt_data(subfolder, model)\n",
    "\n",
    "callbacks = [\n",
    "  # CosineAnnealingScheduler(T_max=4, eta_max=1e-2, eta_min=1e-4),\n",
    "  BackupAndRestore(f'{subfolder}/backup'),\n",
    "  CheckpointAndSave(f'{subfolder}/mse_checkpoint/', demo, model, BATCH_SIZE, save_best_only=True, save_weights_only=True, monitor='val_mse', verbose=1),\n",
    "  CheckpointAndSave(f'{subfolder}/ets_checkpoint/', demo, model, BATCH_SIZE, save_best_only=True, save_weights_only=True, monitor='val_error_to_signal', verbose=1),\n",
    "  CheckpointAndSave(f'{subfolder}/mae_checkpoint/', demo, model, BATCH_SIZE, save_best_only=True, save_weights_only=True, monitor='val_mae', verbose=1),\n",
    "  TensorBoard(log_dir=f'{subfolder}/logs'),\n",
    "  CSVLogger(f'{subfolder}/logs.csv', append=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train, validation_data=valid, shuffle=True, epochs=EPOCHS, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "\n",
    "wavfile.write('out.wav', 44100, pred)\n",
    "wavfile.write('in.wav', 44100, demo.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "0e1565b582b08c8435dd4e4deaf762f9971db0b4896f2676b7c0eb8ce2624cff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
